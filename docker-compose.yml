version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    container_name: licenseplatecontrol-postgres
    restart: unless-stopped
    environment:
      - TZ=Europe/Berlin
      - POSTGRES_USER=lpc
      - POSTGRES_PASSWORD=lpc_secret_2026
      - POSTGRES_DB=licenseplatecontrol
    volumes:
      - pgdata:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - lpc-network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: licenseplatecontrol-backend
    restart: unless-stopped
    ports:
      - "8002:8000"
    volumes:
      - ./volumes/events:/events
    environment:
      - TZ=Europe/Berlin
      - DATABASE_URL=postgresql://lpc:lpc_secret_2026@postgres:5432/licenseplatecontrol
      - ENGINE_URL=http://engine:8000
      - API_KEY=secretmvpkey123
      - HA_URL=http://homeassistant.local:8123
      - HA_TOKEN=optional_long_lived_access_token
      - HA_SERVICE=/api/services/cover/open_cover
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      - engine
      - postgres
      - ollama
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - lpc-network

  engine:
    build:
      context: ./engine
      dockerfile: Dockerfile
    container_name: licenseplatecontrol-engine
    restart: unless-stopped
    ports:
      - "8001:8000"
    volumes:
      - ./volumes/models:/models
      - ./volumes/events:/events
    environment:
      - TZ=Europe/Berlin
      - HF_HOME=/models
      - ORT_OPENVINO_DEVICE=GPU   # Tell onnxruntime-openvino to use Intel GPU (falls back to CPU if unavailable)
    # Intel iGPU passthrough for OpenVINO acceleration
    devices:
      - /dev/dri:/dev/dri
    group_add:
      - "992"   # render group GID (from: getent group render → render:x:992:)
    networks:
      - lpc-network

  ollama:
    image: ollama/ollama:latest
    container_name: licenseplatecontrol-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - TZ=Europe/Berlin
      - OLLAMA_HOST=0.0.0.0
    # GPU passthrough (Intel iGPU) — Ollama nutzt diese automatisch wenn verfügbar
    devices:
      - /dev/dri:/dev/dri
    group_add:
      - "992"   # render group GID
    networks:
      - lpc-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: licenseplatecontrol-frontend
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./frontend/index.html:/usr/share/nginx/html/index.html:ro
      - ./frontend/plates.html:/usr/share/nginx/html/plates.html:ro
      - ./frontend/settings.html:/usr/share/nginx/html/settings.html:ro
      - ./frontend/logs.html:/usr/share/nginx/html/logs.html:ro
    depends_on:
      - backend
    networks:
      - lpc-network

volumes:
  pgdata:
  ollama_data:


networks:
  lpc-network:
    driver: bridge
